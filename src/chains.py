import os
from typing import List
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

load_dotenv()

class MedicalRAGChain:
    def __init__(self, vector_store_manager):
        self.vector_store = vector_store_manager.get_vector_store()
        
        # 1. å®šä¹‰ LLM
        self.llm = ChatOpenAI(
            model="qwen-flash-2025-07-28", 
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            temperature=0
        )
        
        # 2. å®šä¹‰ Prompt æ¨¡æ¿ (RAG çš„çµé­‚)
        self.template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¾å†…ç§‘åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹æä¾›çš„ã€å‚è€ƒèµ„æ–™ã€‘å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
            å¦‚æœä½ åœ¨èµ„æ–™ä¸­æ‰¾ä¸åˆ°ç­”æ¡ˆï¼Œè¯·ç›´æ¥å›ç­”â€œæ ¹æ®ç°æœ‰ä¸´åºŠå…±è¯†ï¼Œæ— æ³•ç»™å‡ºç¡®åˆ‡å»ºè®®â€ï¼Œåˆ‡å‹¿ç¼–é€ ã€‚
            å›ç­”è¯·ä¿æŒä¸“ä¸šã€ä¸¥è°¨ï¼Œå¹¶åˆ—å‡ºå‚è€ƒçš„æ–‡æ¡£æ¥æºã€‚

            ã€å‚è€ƒèµ„æ–™ã€‘
            {context}

            ã€ç”¨æˆ·é—®é¢˜ã€‘
            {question}

            ã€ä¸“å®¶å»ºè®®ã€‘"""
        self.prompt = ChatPromptTemplate.from_template(self.template)

    def _format_docs(self, docs):
        """æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼Œå¸¦ä¸Šæ¥æºï¼Œæ–¹ä¾¿æ¨¡å‹å¼•ç”¨"""
        formatted = []
        for d in docs:
            formatted.append(f"å†…å®¹: {d.page_content}\næ¥æº: {d.metadata.get('source')} (ç¬¬{d.metadata.get('page')}é¡µ)")
        return "\n\n---\n\n".join(formatted)

    def get_chain(self):
        """æ„å»º RAG é“¾"""
        retriever = self.vector_store.as_retriever(search_kwargs={"k": 5})
        
        chain = (
            {"context": retriever | self._format_docs, "question": RunnablePassthrough()}
            | self.prompt
            | self.llm
            | StrOutputParser()
        )
        return chain

if __name__ == "__main__":
    from retrieval import MedicalVectorStore
    from pathlib import Path
    
    # åˆå§‹åŒ–ç¯å¢ƒ
    project_root = Path(__file__).resolve().parent.parent
    db_dir = str(project_root / "data" / "vector_store")
    
    store = MedicalVectorStore(db_dir)
    rag_system = MedicalRAGChain(store)
    
    # ç¬¬ä¸€æ¬¡å®Œæ•´ RAG æµ‹è¯•
    chain = rag_system.get_chain()
    # question = "CKDæ‚£è€…è¡€é’¾ç®¡ç†ä¸­ï¼Œç¯ç¡…é…¸é”†é’ çš„ç”¨æ³•æ˜¯ä»€ä¹ˆï¼Ÿ"
    question = "å¦‚ä½•ä¿®ç†å‘¼å¸æœºï¼Ÿ"
    
    print("\nğŸ©º AI æ­£åœ¨æ€è€ƒä¸­...")
    response = chain.invoke(question)
    print("\n" + "="*50)
    print(response)
    print("="*50)